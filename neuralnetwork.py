# -*- coding: utf-8 -*-
"""NeuralNetwork.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17oLy6rX4HzRKHoPDLSN9voeWiRNpmAKq

# Neural Networks

1.  What is Deep Learning? Briefly describe how it evolved and how it differs from traditional machine learning.
- Deep Learning (DL) is a subfield of machine learning that uses artificial neural networks with many layers (“deep” networks) to automatically learn complex patterns from large amounts of data.

- 1950s–1980s: Early Neural Networks

    Inspired by how the brain works.

    Models like the Perceptron were created.
    
- 1990s–2000s: Machine Learning Era

    Simpler algorithms like SVM, Decision Trees, Random Forest, Logistic Regression became popular.

- 2010s: Rise of Deep Learning

   Availability of big data.

   Advances in GPUs for faster computation.

   Better techniques like ReLU, dropout, backpropagation.

2.  Explain the basic architecture and functioning of a Perceptron. What are its limitations?
- A perceptron has:

    Input features

    Weights

    Bias

    Weighted Sum

    Activation Function

- Limitations:

    - Can learn only linearly separable problems
    - Uses a simple step activation
    - Limited representational power

3. Describe the purpose of activation function in neural networks. Compare Sigmoid, ReLU, and Tanh functions.
- Activation functions are used to:

  - Introduce non-linearity


  - Control the output range


  - Help gradients flow during training

  - Determine whether a neuron should “fire”


- Sigmoid function:

    - Smooth and differentiable.

    - Good for binary classification (output probability).

    - Squashes large values into the [0, 1] range.

- ReLU function:

   - Most widely used activation in deep learning.

  - Very fast to compute.

  - Allows gradients to flow when x>0.

   - Helps solve vanishing gradient problem.

- Tanh function:
  - Zero-centered → better for optimization.

  - Stronger gradients than sigmoid.

4.  What is the difference between Loss function and Cost function in neural networks? Provide examples.
- A loss function measures the error for one training sample or one prediction.
-A cost function is the average of the loss function over all training samples (or a batch).

5.  What is the role of optimizers in neural networks? Compare Gradient Descent, Adam, and RMSprop.  
- Optimizers determine how the network learns by updating weights based on gradients. Their main roles include:

  - Minimizing the loss function

  - Speeding up the training process

  - Handling noisy, sparse, or complex gradients

  - Helping escape local minima or plateaus

  - Ensuring stable and effective convergence

- Gradient Descent:
  - Updates weights by moving them in the direction of negative gradient.

- Adam:
   - Keeps a moving average of squared gradients
   - Gives each parameter its own adaptive learning rate

- RMSProp:
  - Computes first moment (mean of gradients)
  - Computes second moment (mean of squared gradients)
  - Uses bias-corrected estimates
"""

# 6.Write a Python program to implement a single-layer perceptron from scratch using NumPy to solve the logical AND gate.
import numpy as np
X = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])


y = np.array([0, 0, 0, 1])

lr = 0.1
epochs = 20
weights = np.zeros(2)
bias = 0

def step_function(x):
    return 1 if x >= 0 else 0


for epoch in range(epochs):
    for xi, target in zip(X, y):

        z = np.dot(xi, weights) + bias

        pred = step_function(z)
        error = target - pred
        weights += lr * error * xi
        bias += lr * error


    print(f"Epoch {epoch+1}: Weights = {weights}, Bias = {bias}")

print("\nFinal Results:")
for xi in X:
    z = np.dot(xi, weights) + bias
    pred = step_function(z)
    print(f"Input: {xi} → Output: {pred}")

# 7.  Implement and visualize Sigmoid, ReLU, and Tanh activation functions using Matplotlib.
import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(-10, 10, 400)

sigmoid = 1 / (1 + np.exp(-x))
relu = np.maximum(0, x)
tanh = np.tanh(x)

plt.figure(figsize=(10, 6))

plt.subplot(3, 1, 1)
plt.plot(x, sigmoid)
plt.title("Sigmoid")
plt.grid(True)

plt.subplot(3, 1, 2)
plt.plot(x, relu)
plt.title("ReLU")
plt.grid(True)

plt.subplot(3, 1, 3)
plt.plot(x, tanh)
plt.title("Tanh")
plt.grid(True)

plt.tight_layout()
plt.show()

# 8.  Use Keras to build and train a simple multilayer neural network on the MNIST digits dataset. Print the training accuracy.
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train / 255.0
x_test = x_test / 255.0

model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=1)

print("Training Accuracy:", history.history['accuracy'][-1])

# 9. Visualize the loss and accuracy curves for a neural network model trained on the Fashion MNIST dataset. Interpret the training behavior.
import tensorflow as tf
import matplotlib.pyplot as plt


(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

x_train, x_test = x_train / 255.0, x_test / 255.0


model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1)

plt.figure(figsize=(8, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("Loss Curve")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(["Train Loss", "Validation Loss"])
plt.grid(True)
plt.show()

plt.figure(figsize=(8, 5))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title("Accuracy Curve")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend(["Train Accuracy", "Validation Accuracy"])
plt.grid(True)
plt.show()

# 10. You are working on a project for a bank that wants to automatically detect fraudulent transactions. The dataset is large, imbalanced, and contains structured features like transaction amount, merchant ID, and customer location. The goal is to classify each transaction as fraudulent or legitimate.
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping

# Generate some synthetic data to simulate a fraud detection dataset
# In a real scenario, X and y would be loaded from a dataset
n_samples = 1000
n_features = 10
n_fraud = 20 # A small number of fraudulent transactions to simulate imbalance

X = np.random.rand(n_samples, n_features)
y = np.zeros(n_samples, dtype=int)
fraud_indices = np.random.choice(n_samples, n_fraud, replace=False)
y[fraud_indices] = 1


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test  = scaler.transform(X_test)

classes = np.unique(y_train)
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=classes,
    y=y_train
)
class_weight_dict = {cls: w for cls, w in zip(classes, class_weights)}
print("Class weights:", class_weight_dict)

input_dim = X_train.shape[1]

model = Sequential([
    Dense(128, activation='relu', input_shape=(input_dim,),
          kernel_regularizer=l2(1e-4)),
    Dropout(0.3),

    Dense(64, activation='relu',
          kernel_regularizer=l2(1e-4)),
    Dropout(0.3),

    Dense(1, activation='sigmoid')  # fraud probability
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall'),
        tf.keras.metrics.AUC(name='auc_pr', curve='PR')
    ]
)

model.summary()


early_stop = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history = model.fit(
    X_train, y_train,
    epochs=30,
    batch_size=512,
    validation_split=0.2,
    class_weight=class_weight_dict,
    callbacks=[early_stop],
    verbose=1
)

test_metrics = model.evaluate(X_test, y_test, verbose=0)
metric_names = model.metrics_names
for name, value in zip(metric_names, test_metrics):
    print(f"{name}: {value:.4f}")